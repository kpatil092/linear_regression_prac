{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e4f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ad473e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "N, d = 100000, 3\n",
    "X = 2 * np.random.randn(N, d)\n",
    "true_w = np.array([3, -2, 1])\n",
    "true_b = 2\n",
    "noise = np.random.randn(1)\n",
    "y = X @ true_w + true_b + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a70d33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, y_pred):\n",
    "  return np.mean((y - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf06f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.2):\n",
    "  N = len(y)\n",
    "  indices = np.arange(N)\n",
    "  np.random.shuffle(indices)\n",
    "  test_size = int(test_size * N)\n",
    "  test_idx =  indices[:test_size]\n",
    "  train_idx = indices[test_size:]\n",
    "  return X[train_idx], X[test_idx], y[train_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf344470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, lr=0.01, epochs=500): \n",
    "  N, d = X.shape\n",
    "  w = np.random.randn(d)\n",
    "  b = np.random.randn()\n",
    "  loss_history = []\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "\n",
    "    y_pred = X @ w + b\n",
    "    loss = mse(y, y_pred)\n",
    "    loss_history.append(loss)\n",
    "    \n",
    "    dw = (2/N) * (X.T @ (y_pred - y))  \n",
    "    db = (2/N) * np.sum(y_pred - y)\n",
    "    \n",
    "    w -= lr * dw\n",
    "    b -= lr * db\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "      print(f\"Epoch {epoch}: Loss = {loss:.4f}, w = {w}, b = {b:.4f}\")\n",
    "  return w, b, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e750e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "  return X @ w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ad70989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(X, y, k=5, lr=0.01, epochs=500):\n",
    "  N = len(y)\n",
    "  fold_size = N // k\n",
    "  mse_scores = []\n",
    "\n",
    "  for i in range(k):\n",
    "    val_idx = np.arange(i * fold_size, (i + 1) * fold_size)\n",
    "    train_idx = np.setdiff1d(np.arange(N), val_idx) \n",
    "\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "    w, b, _ = train_model(X_train, y_train, lr, epochs)\n",
    "    y_val_pred = predict(X_val, w, b)\n",
    "    val_mse = mse(y_val, y_val_pred)\n",
    "    mse_scores.append(val_mse)\n",
    "\n",
    "    print(f\"Fold {i+1}: Validation MSE = {val_mse:.4f}\")\n",
    "\n",
    "  return mse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13aa88a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 45.0590, w = [ 0.20092127 -0.86494863  1.17361398], b = -0.7809\n",
      "Epoch 10: Loss = 9.5061, w = [ 1.78117564 -1.50189545  1.06887852], b = -0.5280\n",
      "Epoch 20: Loss = 2.4385, w = [ 2.46933862 -1.78137349  1.02724534], b = -0.3215\n",
      "Epoch 30: Loss = 0.8857, w = [ 2.76901415 -1.90400631  1.01081141], b = -0.1529\n",
      "Epoch 40: Loss = 0.4502, w = [ 2.89950734 -1.95782172  1.00436607], b = -0.0151\n",
      "Epoch 50: Loss = 0.2738, w = [ 2.95632263 -1.98144262  1.00184721], b = 0.0975\n",
      "Epoch 60: Loss = 0.1777, w = [ 2.9810522  -1.99181472  1.00085814], b = 0.1894\n",
      "Epoch 70: Loss = 0.1177, w = [ 2.99180981 -1.99637283  1.00046016], b = 0.2646\n",
      "Epoch 80: Loss = 0.0784, w = [ 2.9964842  -1.99837898  1.00028954], b = 0.3260\n",
      "Epoch 90: Loss = 0.0523, w = [ 2.99851093 -1.99926444  1.00020697], b = 0.3761\n",
      "Epoch 100: Loss = 0.0349, w = [ 2.99938606 -1.99965732  1.00015971], b = 0.4171\n",
      "Epoch 110: Loss = 0.0233, w = [ 2.99976095 -1.99983331  1.00012792], b = 0.4506\n",
      "Epoch 120: Loss = 0.0156, w = [ 2.99991908 -1.9999135   1.00010406], b = 0.4780\n",
      "Epoch 130: Loss = 0.0104, w = [ 2.99998372 -1.99995112  1.00008511], b = 0.5003\n",
      "Epoch 140: Loss = 0.0069, w = [ 3.00000842 -1.99996962  1.0000697 ], b = 0.5186\n",
      "Epoch 150: Loss = 0.0046, w = [ 3.00001634 -1.99997937  1.00005708], b = 0.5335\n",
      "Epoch 160: Loss = 0.0031, w = [ 3.00001747 -1.99998498  1.00004672], b = 0.5457\n",
      "Epoch 170: Loss = 0.0021, w = [ 3.00001607 -1.99998853  1.00003821], b = 0.5557\n",
      "Epoch 180: Loss = 0.0014, w = [ 3.00001392 -1.99999099  1.00003125], b = 0.5638\n",
      "Epoch 190: Loss = 0.0009, w = [ 3.00001171 -1.99999279  1.00002554], b = 0.5705\n",
      "Epoch 200: Loss = 0.0006, w = [ 3.00000972 -1.99999418  1.00002088], b = 0.5759\n",
      "Epoch 210: Loss = 0.0004, w = [ 3.000008   -1.99999527  1.00001706], b = 0.5803\n",
      "Epoch 220: Loss = 0.0003, w = [ 3.00000657 -1.99999615  1.00001394], b = 0.5840\n",
      "Epoch 230: Loss = 0.0002, w = [ 3.00000538 -1.99999686  1.00001139], b = 0.5869\n",
      "Epoch 240: Loss = 0.0001, w = [ 3.0000044  -1.99999744  1.00000931], b = 0.5894\n",
      "Epoch 250: Loss = 0.0001, w = [ 3.0000036  -1.99999791  1.00000761], b = 0.5913\n",
      "Epoch 260: Loss = 0.0001, w = [ 3.00000294 -1.99999829  1.00000621], b = 0.5930\n",
      "Epoch 270: Loss = 0.0000, w = [ 3.0000024  -1.9999986   1.00000508], b = 0.5943\n",
      "Epoch 280: Loss = 0.0000, w = [ 3.00000196 -1.99999886  1.00000415], b = 0.5954\n",
      "Epoch 290: Loss = 0.0000, w = [ 3.0000016  -1.99999907  1.00000339], b = 0.5962\n",
      "Epoch 300: Loss = 0.0000, w = [ 3.00000131 -1.99999924  1.00000277], b = 0.5970\n",
      "Epoch 310: Loss = 0.0000, w = [ 3.00000107 -1.99999938  1.00000226], b = 0.5975\n",
      "Epoch 320: Loss = 0.0000, w = [ 3.00000088 -1.99999949  1.00000185], b = 0.5980\n",
      "Epoch 330: Loss = 0.0000, w = [ 3.00000072 -1.99999958  1.00000151], b = 0.5984\n",
      "Epoch 340: Loss = 0.0000, w = [ 3.00000058 -1.99999966  1.00000123], b = 0.5987\n",
      "Epoch 350: Loss = 0.0000, w = [ 3.00000048 -1.99999972  1.00000101], b = 0.5990\n",
      "Epoch 360: Loss = 0.0000, w = [ 3.00000039 -1.99999977  1.00000082], b = 0.5992\n",
      "Epoch 370: Loss = 0.0000, w = [ 3.00000032 -1.99999981  1.00000067], b = 0.5994\n",
      "Epoch 380: Loss = 0.0000, w = [ 3.00000026 -1.99999985  1.00000055], b = 0.5995\n",
      "Epoch 390: Loss = 0.0000, w = [ 3.00000021 -1.99999988  1.00000045], b = 0.5997\n",
      "Epoch 400: Loss = 0.0000, w = [ 3.00000017 -1.9999999   1.00000037], b = 0.5998\n",
      "Epoch 410: Loss = 0.0000, w = [ 3.00000014 -1.99999992  1.0000003 ], b = 0.5998\n",
      "Epoch 420: Loss = 0.0000, w = [ 3.00000012 -1.99999993  1.00000025], b = 0.5999\n",
      "Epoch 430: Loss = 0.0000, w = [ 3.00000009 -1.99999994  1.0000002 ], b = 0.5999\n",
      "Epoch 440: Loss = 0.0000, w = [ 3.00000008 -1.99999995  1.00000016], b = 0.6000\n",
      "Epoch 450: Loss = 0.0000, w = [ 3.00000006 -1.99999996  1.00000013], b = 0.6000\n",
      "Epoch 460: Loss = 0.0000, w = [ 3.00000005 -1.99999997  1.00000011], b = 0.6001\n",
      "Epoch 470: Loss = 0.0000, w = [ 3.00000004 -1.99999998  1.00000009], b = 0.6001\n",
      "Epoch 480: Loss = 0.0000, w = [ 3.00000003 -1.99999998  1.00000007], b = 0.6001\n",
      "Epoch 490: Loss = 0.0000, w = [ 3.00000003 -1.99999998  1.00000006], b = 0.6001\n",
      "Test MSE: 3.3393188085932473e-09\n",
      "Learned w: [ 3.00000002 -1.99999999  1.00000005], b: 0.6001205150767458\n",
      "True w: [ 3 -2  1], b: 2\n"
     ]
    }
   ],
   "source": [
    "# Test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train model on training data\n",
    "w, b, loss_history = train_model(X_train, y_train)\n",
    "\n",
    "# Test model on test data (Predict)\n",
    "y_test_pred = predict(X_test, w, b)\n",
    "\n",
    "# Validate model with respect to test data\n",
    "test_mse = mse(y_test, y_test_pred)\n",
    "print(f\"Test MSE: {test_mse}\")\n",
    "print(f\"Learned w: {w}, b: {b}\")\n",
    "print(f\"True w: {true_w}, b: {true_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cb733e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running 5-Fold Cross Validation:\n",
      "Epoch 0: Loss = 57.4378, w = [ 0.1944933  -0.57112381 -0.46136974], b = -0.4022\n",
      "Epoch 10: Loss = 11.4965, w = [ 1.77369953 -1.37448767  0.35857982], b = -0.2172\n",
      "Epoch 20: Loss = 2.5319, w = [ 2.46414412 -1.72628347  0.71847435], b = -0.0670\n",
      "Epoch 30: Loss = 0.7051, w = [ 2.76598529 -1.88031476  0.87643592], b = 0.0554\n",
      "Epoch 40: Loss = 0.2820, w = [ 2.89791677 -1.94773942  0.94576538], b = 0.1552\n",
      "Epoch 50: Loss = 0.1521, w = [ 2.95556221 -1.97723994  0.97619372], b = 0.2367\n",
      "Epoch 60: Loss = 0.0946, w = [ 2.98073262 -1.99013645  0.98954858], b = 0.3032\n",
      "Epoch 70: Loss = 0.0618, w = [ 2.99170915 -1.99576541  0.99541015], b = 0.3575\n",
      "Epoch 80: Loss = 0.0410, w = [ 2.99648445 -1.99821502  0.99798306], b = 0.4019\n",
      "Epoch 90: Loss = 0.0273, w = [ 2.99855255 -1.99927509  0.99911264], b = 0.4382\n",
      "Epoch 100: Loss = 0.0182, w = [ 2.99944048 -1.99972894  0.99960874], b = 0.4678\n",
      "Epoch 110: Loss = 0.0122, w = [ 2.99981534 -1.99991921  0.99982677], b = 0.4920\n",
      "Epoch 120: Loss = 0.0081, w = [ 2.99996829 -1.9999956   0.99992273], b = 0.5118\n",
      "Epoch 130: Loss = 0.0054, w = [ 3.0000262  -2.00002339  0.99996506], b = 0.5280\n",
      "Epoch 140: Loss = 0.0036, w = [ 3.0000442  -2.00003092  0.99998382], b = 0.5412\n",
      "Epoch 150: Loss = 0.0024, w = [ 3.00004608 -2.00003044  0.99999221], b = 0.5520\n",
      "Epoch 160: Loss = 0.0016, w = [ 3.00004201 -2.00002714  0.99999602], b = 0.5608\n",
      "Epoch 170: Loss = 0.0011, w = [ 3.00003623 -2.00002317  0.99999779], b = 0.5680\n",
      "Epoch 180: Loss = 0.0007, w = [ 3.00003044 -2.00001936  0.99999865], b = 0.5739\n",
      "Epoch 190: Loss = 0.0005, w = [ 3.00002523 -2.00001601  0.9999991 ], b = 0.5787\n",
      "Fold 1: Validation MSE = 0.0003\n",
      "Epoch 0: Loss = 67.0769, w = [ 0.7643979  -1.51516429 -2.00004128], b = 0.9379\n",
      "Epoch 10: Loss = 12.7990, w = [ 2.0243526  -1.78608928 -0.30623936], b = 0.8766\n",
      "Epoch 20: Loss = 2.4695, w = [ 2.57426284 -1.90555599  0.43120886], b = 0.8262\n",
      "Epoch 30: Loss = 0.4946, w = [ 2.81426276 -1.95824203  0.7522892 ], b = 0.7849\n",
      "Epoch 40: Loss = 0.1110, w = [ 2.91899958 -1.98148552  0.89209272], b = 0.7512\n",
      "Epoch 50: Loss = 0.0324, w = [ 2.96470117 -1.99174818  0.95297087], b = 0.7236\n",
      "Epoch 60: Loss = 0.0137, w = [ 2.98463817 -1.99628686  0.97948486], b = 0.7010\n",
      "Epoch 70: Loss = 0.0077, w = [ 2.99333171 -1.99830043  0.99103582], b = 0.6826\n",
      "Epoch 80: Loss = 0.0048, w = [ 2.99711939 -1.99919899  0.99607083], b = 0.6675\n",
      "Epoch 90: Loss = 0.0032, w = [ 2.9987671  -1.99960431  0.99826783], b = 0.6552\n",
      "Epoch 100: Loss = 0.0021, w = [ 2.99948179 -1.99979063  0.9992283 ], b = 0.6451\n",
      "Epoch 110: Loss = 0.0014, w = [ 2.99979008 -1.99987909  0.99964969], b = 0.6369\n",
      "Epoch 120: Loss = 0.0009, w = [ 2.99992166 -1.99992329  0.99983578], b = 0.6302\n",
      "Epoch 130: Loss = 0.0006, w = [ 2.99997666 -1.99994704  0.99991895], b = 0.6247\n",
      "Epoch 140: Loss = 0.0004, w = [ 2.99999868 -1.99996101  0.9999569 ], b = 0.6202\n",
      "Epoch 150: Loss = 0.0003, w = [ 3.00000667 -1.99997002  0.99997486], b = 0.6165\n",
      "Epoch 160: Loss = 0.0002, w = [ 3.00000883 -1.99997633  0.99998384], b = 0.6136\n",
      "Epoch 170: Loss = 0.0001, w = [ 3.00000869 -1.99998103  0.99998871], b = 0.6111\n",
      "Epoch 180: Loss = 0.0001, w = [ 3.00000774 -1.99998466  0.9999916 ], b = 0.6091\n",
      "Epoch 190: Loss = 0.0001, w = [ 3.00000661 -1.99998753  0.9999935 ], b = 0.6075\n",
      "Fold 2: Validation MSE = 0.0000\n",
      "Epoch 0: Loss = 9.7976, w = [ 2.54101243 -0.72954728  0.49476882], b = 0.6171\n",
      "Epoch 10: Loss = 1.8580, w = [ 2.79977265 -1.4468497   0.78013785], b = 0.6142\n",
      "Epoch 20: Loss = 0.3524, w = [ 2.91265833 -1.75915946  0.90431855], b = 0.6117\n",
      "Epoch 30: Loss = 0.0669, w = [ 2.96190386 -1.89513783  0.9583577 ], b = 0.6096\n",
      "Epoch 40: Loss = 0.0127, w = [ 2.98338598 -1.95434242  0.98187429], b = 0.6079\n",
      "Epoch 50: Loss = 0.0024, w = [ 2.99275643 -1.98012005  0.99210861], b = 0.6065\n",
      "Epoch 60: Loss = 0.0005, w = [ 2.9968434  -1.99134369  0.99656289], b = 0.6053\n",
      "Epoch 70: Loss = 0.0001, w = [ 2.99862565 -1.99623055  0.9985018 ], b = 0.6044\n",
      "Epoch 80: Loss = 0.0000, w = [ 2.99940263 -1.99835837  0.999346  ], b = 0.6036\n",
      "Epoch 90: Loss = 0.0000, w = [ 2.99974116 -1.9992849   0.99971374], b = 0.6030\n",
      "Epoch 100: Loss = 0.0000, w = [ 2.99988851 -1.99968837  0.99987407], b = 0.6025\n",
      "Epoch 110: Loss = 0.0000, w = [ 2.99995253 -1.99986409  0.9999441 ], b = 0.6021\n",
      "Epoch 120: Loss = 0.0000, w = [ 2.99998024 -1.99994064  0.99997477], b = 0.6017\n",
      "Epoch 130: Loss = 0.0000, w = [ 2.99999215 -1.999974    0.99998828], b = 0.6014\n",
      "Epoch 140: Loss = 0.0000, w = [ 2.99999721 -1.99998856  0.9999943 ], b = 0.6012\n",
      "Epoch 150: Loss = 0.0000, w = [ 2.9999993  -1.99999492  0.99999703], b = 0.6010\n",
      "Epoch 160: Loss = 0.0000, w = [ 3.00000011 -1.9999977   0.9999983 ], b = 0.6009\n",
      "Epoch 170: Loss = 0.0000, w = [ 3.00000039 -1.99999893  0.99999893], b = 0.6007\n",
      "Epoch 180: Loss = 0.0000, w = [ 3.00000045 -1.99999948  0.99999927], b = 0.6006\n",
      "Epoch 190: Loss = 0.0000, w = [ 3.00000043 -1.99999973  0.99999946], b = 0.6006\n",
      "Fold 3: Validation MSE = 0.0000\n",
      "Epoch 0: Loss = 68.1293, w = [ 0.49135217  0.48751645 -0.24352779], b = -0.9297\n",
      "Epoch 10: Loss = 14.1935, w = [ 1.90113588 -0.91563151  0.45256221], b = -0.6491\n",
      "Epoch 20: Loss = 3.4887, w = [ 2.51843976 -1.52737033  0.75967155], b = -0.4202\n",
      "Epoch 30: Loss = 1.1835, w = [ 2.78878272 -1.79406659  0.8950266 ], b = -0.2334\n",
      "Epoch 40: Loss = 0.5709, w = [ 2.90721119 -1.91032729  0.95457869], b = -0.0809\n",
      "Epoch 50: Loss = 0.3392, w = [ 2.95911815 -1.9609996   0.98069867], b = 0.0437\n",
      "Epoch 60: Loss = 0.2184, w = [ 2.98189091 -1.98307705  0.99209031], b = 0.1455\n",
      "Epoch 70: Loss = 0.1443, w = [ 2.99189974 -1.99268908  0.99700603], b = 0.2287\n",
      "Epoch 80: Loss = 0.0960, w = [ 2.99631326 -1.99686815  0.99908417], b = 0.2967\n",
      "Epoch 90: Loss = 0.0641, w = [ 2.99827127 -1.99868033  0.99992684], b = 0.3522\n",
      "Epoch 100: Loss = 0.0428, w = [ 2.99914951 -1.99946221  1.00023801], b = 0.3975\n",
      "Epoch 110: Loss = 0.0285, w = [ 2.99955116 -1.9997963   1.0003258 ], b = 0.4346\n",
      "Epoch 120: Loss = 0.0191, w = [ 2.99974101 -1.99993637  1.00032411], b = 0.4649\n",
      "Epoch 130: Loss = 0.0127, w = [ 2.99983556 -1.99999285  1.00029035], b = 0.4896\n",
      "Epoch 140: Loss = 0.0085, w = [ 2.99988629 -2.00001372  1.00024849], b = 0.5099\n",
      "Epoch 150: Loss = 0.0057, w = [ 2.99991614 -2.00001974  1.000208  ], b = 0.5264\n",
      "Epoch 160: Loss = 0.0038, w = [ 2.99993544 -2.00001985  1.00017214], b = 0.5399\n",
      "Epoch 170: Loss = 0.0025, w = [ 2.99994898 -2.00001784  1.00014161], b = 0.5509\n",
      "Epoch 180: Loss = 0.0017, w = [ 2.99995907 -2.00001529  1.00011613], b = 0.5599\n",
      "Epoch 190: Loss = 0.0011, w = [ 2.99996689 -2.0000128   1.00009508], b = 0.5673\n",
      "Fold 4: Validation MSE = 0.0008\n",
      "Epoch 0: Loss = 55.3063, w = [0.71447563 0.29159876 0.12717606], b = -0.9674\n",
      "Epoch 10: Loss = 11.7594, w = [ 2.00368996 -0.99910817  0.61660442], b = -0.6810\n",
      "Epoch 20: Loss = 3.0564, w = [ 2.56570969 -1.56266086  0.8317758 ], b = -0.4468\n",
      "Epoch 30: Loss = 1.1270, w = [ 2.81071429 -1.80875442  0.92633471], b = -0.2553\n",
      "Epoch 40: Loss = 0.5784, w = [ 2.91751769 -1.91624657  0.96786051], b = -0.0989\n",
      "Epoch 50: Loss = 0.3530, w = [ 2.96407297 -1.96322095  0.98607419], b = 0.0290\n",
      "Epoch 60: Loss = 0.2293, w = [ 2.98436368 -1.98376727  0.99404502], b = 0.1335\n",
      "Epoch 70: Loss = 0.1519, w = [ 2.993205   -1.99276913  0.99751883], b = 0.2188\n",
      "Epoch 80: Loss = 0.1012, w = [ 2.9970556  -1.99672532  0.99902101], b = 0.2886\n",
      "Epoch 90: Loss = 0.0675, w = [ 2.99873109 -1.99847399  0.99966094], b = 0.3456\n",
      "Epoch 100: Loss = 0.0451, w = [ 2.99945888 -1.99925501  0.99992553], b = 0.3922\n",
      "Epoch 110: Loss = 0.0301, w = [ 2.99977398 -1.99961038  1.0000282 ], b = 0.4302\n",
      "Epoch 120: Loss = 0.0201, w = [ 2.99990955 -1.9997773   1.00006218], b = 0.4613\n",
      "Epoch 130: Loss = 0.0134, w = [ 2.99996718 -1.99985979  1.000068  ], b = 0.4867\n",
      "Epoch 140: Loss = 0.0090, w = [ 2.99999109 -1.99990366  1.00006312], b = 0.5075\n",
      "Epoch 150: Loss = 0.0060, w = [ 3.00000053 -1.99992924  1.0000549 ], b = 0.5244\n",
      "Epoch 160: Loss = 0.0040, w = [ 3.00000384 -1.99994566  1.00004631], b = 0.5383\n",
      "Epoch 170: Loss = 0.0027, w = [ 3.00000462 -1.99995712  1.00003848], b = 0.5496\n",
      "Epoch 180: Loss = 0.0018, w = [ 3.00000442 -1.99996562  1.00003173], b = 0.5589\n",
      "Epoch 190: Loss = 0.0012, w = [ 3.0000039  -1.9999722   1.00002605], b = 0.5664\n",
      "Fold 5: Validation MSE = 0.0008\n",
      "Average CV MSE = 0.0004\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRunning 5-Fold Cross Validation:\")\n",
    "cv_scores = k_fold_cross_validation(X, y, k=5, lr=0.01, epochs=200)\n",
    "print(f\"Average CV MSE = {np.mean(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf22c120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
